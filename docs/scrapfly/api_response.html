<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>scrapfly.api_response API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>scrapfly.api_response</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import base64
import binascii
import hashlib
import hmac
import re
import logging as logger
import shutil

from base64 import b64decode
from contextlib import suppress
from datetime import datetime
from functools import partial

try:
    from functools import cached_property
except ImportError:
    from .polyfill.cached_property import cached_property

from http.cookiejar import Cookie
from http.cookies import SimpleCookie
from io import BytesIO
from json import JSONDecoder, loads

from dateutil.parser import parse
from requests import Request, Response, HTTPError
from typing import Dict, Optional, Iterable, Union, TextIO, Tuple

from requests.structures import CaseInsensitiveDict

from .scrape_config import ScrapeConfig
from .errors import ErrorFactory, EncoderError, ApiHttpClientError, ApiHttpServerError, UpstreamHttpError, HttpError, \
    ExtraUsageForbidden, WebhookSignatureMissMatch
from .frozen_dict import FrozenDict

logger.getLogger(__name__)

_DATE_FORMAT = &#39;%Y-%m-%d %H:%M:%S&#39;


def _date_parser(value):
    if isinstance(value, Dict):
        over = value.items()
    else:
        over = enumerate(value)

    for k, v in over:
        if isinstance(v, str):
            if len(v) &lt;= 26:
                try:
                    value[k] = datetime.strptime(v, _DATE_FORMAT)
                except ValueError:
                    value[k] = v
            else:
                value[k] = v
        elif isinstance(v, Iterable):
            value[k] = _date_parser(v)
        else:
            value[k] = v

    return value


class ResponseBodyHandler:

    SUPPORTED_COMPRESSION = [&#39;gzip&#39;, &#39;deflate&#39;]
    SUPPORTED_CONTENT_TYPES = [&#39;application/msgpack&#39;, &#39;application/json&#39;]

    class JSONDateTimeDecoder(JSONDecoder):
        def __init__(self, *args, **kargs):
            JSONDecoder.__init__(self, *args, object_hook=_date_parser, **kargs)

    # brotli under perform at same gzip level and upper level destroy the cpu so
    # the trade off do not worth it for most of usage
    def __init__(self, use_brotli:bool=False, signing_secrets:Optional[Tuple[str]]=None):
        if use_brotli is True and &#39;br&#39; not in self.SUPPORTED_COMPRESSION:
            try:
                try:
                    import brotlicffi as brotli
                    self.SUPPORTED_COMPRESSION.insert(0, &#39;br&#39;)
                except ImportError:
                    import brotli
                    self.SUPPORTED_COMPRESSION.insert(0, &#39;br&#39;)
            except ImportError:
                pass

        self.content_encoding:str = &#39;, &#39;.join(self.SUPPORTED_COMPRESSION)
        self._signing_secret:Optional[Tuple[str]] = None

        if signing_secrets:
            _secrets = set()

            for signing_secret in signing_secrets:
                _secrets.add(binascii.unhexlify(signing_secret))

            self._signing_secret = tuple(_secrets)

        try:  # automatically use msgpack if available https://msgpack.org/
            import msgpack
            self.accept = &#39;application/msgpack;charset=utf-8&#39;
            self.content_type = &#39;application/msgpack;charset=utf-8&#39;
            self.content_loader = partial(msgpack.loads, object_hook=_date_parser, strict_map_key=False)
        except ImportError:
            self.accept = &#39;application/json;charset=utf-8&#39;
            self.content_type = &#39;application/json;charset=utf-8&#39;
            self.content_loader = partial(loads, cls=self.JSONDateTimeDecoder)

    def support(self, headers:Dict) -&gt; bool:
        if &#39;content-type&#39; not in headers:
            return False

        for content_type in self.SUPPORTED_CONTENT_TYPES:
            if headers[&#39;content-type&#39;].find(content_type) != -1:
                return True

        return False

    def verify(self, message:bytes, signature:str) -&gt; bool:
        for signing_secret in self._signing_secret:
            if hmac.new(signing_secret, message, hashlib.sha256).hexdigest().upper() == signature:
                return True

        return False

    def read(self, content: bytes, content_encoding:str, content_type:str, signature:Optional[str]) -&gt; Dict:
        if content_encoding == &#39;gzip&#39;:
            import gzip
            content = gzip.decompress(content)
        elif content_encoding == &#39;deflate&#39;:
            import zlib
            content = zlib.decompress(content)
        elif content_encoding == &#39;brotli&#39;:
            import brotli
            content = brotli.decompress(content)

        if self._signing_secret is not None and signature is not None:
            if not self.verify(content, signature):
                raise WebhookSignatureMissMatch()

        if content_type.startswith(&#39;application/json&#39;):
            content = loads(content, cls=self.JSONDateTimeDecoder)
        elif content_type.startswith(&#39;application/msgpack&#39;):
            import msgpack
            content = msgpack.loads(content, object_hook=_date_parser, strict_map_key=False)

        return content

    def __call__(self, content: bytes) -&gt; Union[str, Dict]:
        try:
            return self.content_loader(content)
        except Exception as e:
            try:
                raise EncoderError(content=content.decode(&#39;utf-8&#39;)) from e
            except UnicodeError:
                raise EncoderError(content=base64.b64encode(content).decode(&#39;utf-8&#39;)) from e


class ScrapeApiResponse:

    def __init__(self, request: Request, response: Response, scrape_config: ScrapeConfig, api_result: Optional[Dict] = None):
        self.request = request
        self.response = response
        self.scrape_config = scrape_config

        if self.scrape_config.method == &#39;HEAD&#39;:
            api_result = {
                &#39;result&#39;: {
                    &#39;request_headers&#39;: {},
                    &#39;status&#39;: &#39;DONE&#39;,
                    &#39;success&#39;: 200 &gt;= self.response.status_code &lt; 300,
                    &#39;response_headers&#39;: self.response.headers,
                    &#39;status_code&#39;: self.response.status_code,
                    &#39;reason&#39;: self.response.reason,
                    &#39;format&#39;: &#39;text&#39;,
                    &#39;content&#39;: &#39;&#39;
                },
                &#39;context&#39;: {},
                &#39;config&#39;: self.scrape_config.__dict__
            }

            if &#39;X-Scrapfly-Reject-Code&#39; in self.response.headers:
                api_result[&#39;result&#39;][&#39;error&#39;] = {
                    &#39;code&#39;: self.response.headers[&#39;X-Scrapfly-Reject-Code&#39;],
                    &#39;http_code&#39;: int(self.response.headers[&#39;X-Scrapfly-Reject-Http-Code&#39;]),
                    &#39;message&#39;: self.response.headers[&#39;X-Scrapfly-Reject-Description&#39;],
                    &#39;error_id&#39;: self.response.headers[&#39;X-Scrapfly-Reject-ID&#39;],
                    &#39;retryable&#39;: True if self.response.headers[&#39;X-Scrapfly-Reject-Retryable&#39;] == &#39;yes&#39; else False,
                    &#39;doc_url&#39;: &#39;&#39;,
                    &#39;links&#39;: {}
                }

                if &#39;X-Scrapfly-Reject-Doc&#39; in self.response.headers:
                    api_result[&#39;result&#39;][&#39;error&#39;][&#39;doc_url&#39;] = self.response.headers[&#39;X-Scrapfly-Reject-Doc&#39;]
                    api_result[&#39;result&#39;][&#39;error&#39;][&#39;links&#39;][&#39;Related Docs&#39;] = self.response.headers[&#39;X-Scrapfly-Reject-Doc&#39;]

        if isinstance(api_result, str):
            raise HttpError(
                request=request,
                response=response,
                message=&#39;Bad gateway&#39;,
                code=502,
                http_status_code=502,
                is_retryable=True
            )

        self.result = self.handle_api_result(api_result=api_result)

    @property
    def scrape_result(self) -&gt; Dict:
        return self.result[&#39;result&#39;]

    @property
    def config(self) -&gt; Dict:
        return self.result[&#39;config&#39;]

    @property
    def context(self) -&gt; Dict:
        return self.result[&#39;context&#39;]

    @property
    def content(self) -&gt; str:
        return self.scrape_result[&#39;content&#39;]

    @property
    def success(self) -&gt; bool:
        &#34;&#34;&#34;
            /!\ Success means Scrapfly api reply correctly to the call, but the scrape can be unsuccessful if the upstream reply with error status code
        &#34;&#34;&#34;
        return 200 &gt;= self.response.status_code &lt;= 299

    @property
    def scrape_success(self) -&gt; bool:
        return self.scrape_result[&#39;success&#39;]

    @property
    def error(self) -&gt; Optional[Dict]:
        if self.scrape_success is False:
            return self.scrape_result[&#39;error&#39;]

    @property
    def status_code(self) -&gt; int:
        &#34;&#34;&#34;
            /!\ This is the status code of our API, not the upstream website
        &#34;&#34;&#34;
        return self.response.status_code

    @property
    def upstream_status_code(self) -&gt; Optional[int]:
        if &#39;status_code&#39; in self.scrape_result:
            return self.scrape_result[&#39;status_code&#39;]

        return None

    def prevent_extra_usage(self):
        if self.remaining_quota == 0:
            raise ExtraUsageForbidden(
                message=&#39;All Pre Paid Quota Used&#39;,
                code=&#39;ERR::ACCOUNT::PREVENT_EXTRA_USAGE&#39;,
                http_status_code=429,
                is_retryable=False
            )

    @property
    def remaining_quota(self) -&gt; Optional[int]:
        remaining_scrape = self.response.headers.get(&#39;X-Scrapfly-Remaining-Scrape&#39;)

        if remaining_scrape:
            remaining_scrape = int(remaining_scrape)

        return remaining_scrape

    @property
    def cost(self) -&gt; Optional[int]:
        cost = self.response.headers.get(&#39;X-Scrapfly-Api-Cost&#39;)

        if cost:
            cost = int(cost)

        return cost

    @property
    def duration_ms(self) -&gt; Optional[float]:
        duration = self.response.headers.get(&#39;X-Scrapfly-Response-Time&#39;)

        if duration:
            duration = float(duration)

        return duration

    @property
    def headers(self) -&gt; CaseInsensitiveDict:
        return self.response.headers

    def handle_api_result(self, api_result: Dict) -&gt; Optional[FrozenDict]:
        if self._is_api_error(api_result=api_result) is True:
            return FrozenDict(api_result)

        try:
            if isinstance(api_result[&#39;config&#39;][&#39;headers&#39;], list):
                api_result[&#39;config&#39;][&#39;headers&#39;] = {}
        except TypeError:
            logger.info(api_result)
            raise

        with suppress(KeyError):
            api_result[&#39;result&#39;][&#39;request_headers&#39;] = CaseInsensitiveDict(api_result[&#39;result&#39;][&#39;request_headers&#39;])
            api_result[&#39;result&#39;][&#39;response_headers&#39;] = CaseInsensitiveDict(api_result[&#39;result&#39;][&#39;response_headers&#39;])

        if api_result[&#39;result&#39;][&#39;format&#39;] == &#39;binary&#39; and api_result[&#39;result&#39;][&#39;content&#39;]:
            api_result[&#39;result&#39;][&#39;content&#39;] = BytesIO(b64decode(api_result[&#39;result&#39;][&#39;content&#39;]))

        return FrozenDict(api_result)

    @cached_property
    def soup(self) -&gt; &#39;BeautifulSoup&#39;:
        try:
            from bs4 import BeautifulSoup
            soup = BeautifulSoup(self.content, &#34;lxml&#34;)
            return soup
        except ImportError as e:
            logger.error(&#39;You must install scrapfly[parser] to enable this feature&#39;)

    @cached_property
    def selector(self) -&gt; &#39;Selector&#39;:
        try:
            from parsel import Selector
            return Selector(text=self.content)
        except ImportError as e:
            logger.error(&#39;You must install parsel or scrapy package to enable this feature&#39;)
            raise e

    @property
    def error_message(self) :
        if self.error:
            message = &#34;&lt;-- %s | %s - %s.&#34; % (self.response.status_code, self.error[&#39;code&#39;], self.error[&#39;message&#39;])

            if self.error[&#39;links&#39;]:
                message += &#34;Checkout the related doc: %s&#34; % list(self.error[&#39;links&#39;].values())[0]

            return message

        return &#39;&lt;-- %s - %s %s | Doc: %s&#39; % (self.response.status_code, self.http_status_code, self.code, self.documentation_url)

    def _is_api_error(self, api_result: Dict) -&gt; bool:
        if self.scrape_config.method == &#39;HEAD&#39;:
            if &#39;X-Reject-Reason&#39; in self.response.headers:
                return True
            return False

        if api_result is None:
            return True

        return &#39;error_id&#39; in api_result

    def raise_for_result(self, raise_on_upstream_error: bool = True):

        try:
            self.response.raise_for_status()
        except HTTPError as e:
            if &#39;http_code&#39; in self.result:
                if e.response.status_code &gt;= 500:
                    raise ApiHttpServerError(
                        request=e.request,
                        response=e.response,
                        message=self.result[&#39;message&#39;],
                        code=&#39;&#39;,
                        resource=&#39;&#39;,
                        http_status_code=e.response.status_code,
                        documentation_url=self.result.get(&#39;links&#39;)
                    ) from e
                else:
                    raise ApiHttpClientError(
                        request=e.request,
                        response=e.response,
                        message=self.result[&#39;message&#39;],
                        code=&#39;&#39;,
                        resource=&#39;API&#39;,
                        http_status_code=self.result[&#39;http_code&#39;],
                        documentation_url=self.result.get(&#39;links&#39;)
                    ) from e

        if self.result[&#39;result&#39;][&#39;status&#39;] == &#39;DONE&#39; and self.scrape_success is False:
            error = ErrorFactory.create(api_response=self)

            if error:
                if isinstance(error, UpstreamHttpError):
                    if raise_on_upstream_error is True:
                        raise error
                else:
                    raise error

    def upstream_result_into_response(self, _class=Response) -&gt; Optional[Response]:
        if _class != Response:
            raise RuntimeError(&#39;only Response from requests package is supported at the moment&#39;)

        if self.result is None:
            return None

        if self.response.status_code != 200:
            return None

        response = Response()
        response.status_code = self.scrape_result[&#39;status_code&#39;]
        response.reason = self.scrape_result[&#39;reason&#39;]

        if self.scrape_result[&#39;content&#39;]:
            if isinstance(self.scrape_result[&#39;content&#39;], BytesIO):
                response._content = self.scrape_result[&#39;content&#39;].getvalue()
            elif isinstance(self.scrape_result[&#39;content&#39;], bytes):
                response._content = self.scrape_result[&#39;content&#39;]
            elif isinstance(self.scrape_result[&#39;content&#39;], str):
                response._content = self.scrape_result[&#39;content&#39;].encode(&#39;utf-8&#39;)
        else:
            response._content = None

        response.headers.update(self.scrape_result[&#39;response_headers&#39;])
        response.url = self.scrape_result[&#39;url&#39;]

        response.request = Request(
            method=self.config[&#39;method&#39;],
            url=self.config[&#39;url&#39;],
            headers=self.scrape_result[&#39;request_headers&#39;],
            data=self.config[&#39;body&#39;] if self.config[&#39;body&#39;] else None
        )

        if &#39;set-cookie&#39; in response.headers:
            for raw_cookie in response.headers[&#39;set-cookie&#39;]:
                for name, cookie in SimpleCookie(raw_cookie).items():
                    expires = cookie.get(&#39;expires&#39;)

                    if expires == &#39;&#39;:
                        expires = None

                    if expires:
                        try:
                            expires = parse(expires).timestamp()
                        except ValueError:
                            expires = None

                    if type(expires) == str:
                        if &#39;.&#39; in expires:
                            expires = float(expires)
                        else:
                            expires = int(expires)

                    response.cookies.set_cookie(Cookie(
                        version=cookie.get(&#39;version&#39;) if cookie.get(&#39;version&#39;) else None,
                        name=name,
                        value=cookie.value,
                        path=cookie.get(&#39;path&#39;, &#39;&#39;),
                        expires=expires,
                        comment=cookie.get(&#39;comment&#39;),
                        domain=cookie.get(&#39;domain&#39;, &#39;&#39;),
                        secure=cookie.get(&#39;secure&#39;),
                        port=None,
                        port_specified=False,
                        domain_specified=cookie.get(&#39;domain&#39;) is not None and cookie.get(&#39;domain&#39;) != &#39;&#39;,
                        domain_initial_dot=bool(cookie.get(&#39;domain&#39;).startswith(&#39;.&#39;)) if cookie.get(&#39;domain&#39;) is not None else False,
                        path_specified=cookie.get(&#39;path&#39;) != &#39;&#39; and cookie.get(&#39;path&#39;) is not None,
                        discard=False,
                        comment_url=None,
                        rest={
                            &#39;httponly&#39;: cookie.get(&#39;httponly&#39;),
                            &#39;samesite&#39;: cookie.get(&#39;samesite&#39;),
                            &#39;max-age&#39;: cookie.get(&#39;max-age&#39;)
                        }
                    ))

        return response

    def sink(self, path: Optional[str] = None, name: Optional[str] = None, file: Optional[Union[TextIO, BytesIO]] = None, content:Optional[Union[str, bytes]]=None):
        file_content = content or self.scrape_result[&#39;content&#39;]
        file_path = None
        file_extension = None

        if name:
            name_parts = name.split(&#39;.&#39;)
            if len(name_parts) &gt; 1:
                file_extension = name_parts[-1]

        if not file:
            if file_extension is None:
                try:
                    mime_type = self.scrape_result[&#39;response_headers&#39;][&#39;content-type&#39;]
                except KeyError:
                    mime_type = &#39;application/octet-stream&#39;

                if &#39;;&#39; in mime_type:
                    mime_type = mime_type.split(&#39;;&#39;)[0]

                file_extension = &#39;.&#39; + mime_type.split(&#39;/&#39;)[1]

            if not name:
                name = self.config[&#39;url&#39;].split(&#39;/&#39;)[-1]

            if name.find(file_extension) == -1:
                name += file_extension

            file_path = path + &#39;/&#39; + name if path is not None else name

            if file_path == file_extension:
                url = re.sub(r&#39;(https|http)?://&#39;, &#39;&#39;, self.config[&#39;url&#39;]).replace(&#39;/&#39;, &#39;-&#39;)

                if url[-1] == &#39;-&#39;:
                    url = url[:-1]

                url += file_extension

                file_path = url

            file = open(file_path, &#39;wb&#39;)

        if isinstance(file_content, str):
            file_content = BytesIO(file_content.encode(&#39;utf-8&#39;))
        elif isinstance(file_content, bytes):
            file_content = BytesIO(file_content)

        file_content.seek(0)
        with file as f:
            shutil.copyfileobj(file_content, f, length=131072)

        logger.info(&#39;file %s created&#39; % file_path)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="scrapfly.api_response.ResponseBodyHandler"><code class="flex name class">
<span>class <span class="ident">ResponseBodyHandler</span></span>
<span>(</span><span>use_brotli: bool = False, signing_secrets: Optional[Tuple[str]] = None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ResponseBodyHandler:

    SUPPORTED_COMPRESSION = [&#39;gzip&#39;, &#39;deflate&#39;]
    SUPPORTED_CONTENT_TYPES = [&#39;application/msgpack&#39;, &#39;application/json&#39;]

    class JSONDateTimeDecoder(JSONDecoder):
        def __init__(self, *args, **kargs):
            JSONDecoder.__init__(self, *args, object_hook=_date_parser, **kargs)

    # brotli under perform at same gzip level and upper level destroy the cpu so
    # the trade off do not worth it for most of usage
    def __init__(self, use_brotli:bool=False, signing_secrets:Optional[Tuple[str]]=None):
        if use_brotli is True and &#39;br&#39; not in self.SUPPORTED_COMPRESSION:
            try:
                try:
                    import brotlicffi as brotli
                    self.SUPPORTED_COMPRESSION.insert(0, &#39;br&#39;)
                except ImportError:
                    import brotli
                    self.SUPPORTED_COMPRESSION.insert(0, &#39;br&#39;)
            except ImportError:
                pass

        self.content_encoding:str = &#39;, &#39;.join(self.SUPPORTED_COMPRESSION)
        self._signing_secret:Optional[Tuple[str]] = None

        if signing_secrets:
            _secrets = set()

            for signing_secret in signing_secrets:
                _secrets.add(binascii.unhexlify(signing_secret))

            self._signing_secret = tuple(_secrets)

        try:  # automatically use msgpack if available https://msgpack.org/
            import msgpack
            self.accept = &#39;application/msgpack;charset=utf-8&#39;
            self.content_type = &#39;application/msgpack;charset=utf-8&#39;
            self.content_loader = partial(msgpack.loads, object_hook=_date_parser, strict_map_key=False)
        except ImportError:
            self.accept = &#39;application/json;charset=utf-8&#39;
            self.content_type = &#39;application/json;charset=utf-8&#39;
            self.content_loader = partial(loads, cls=self.JSONDateTimeDecoder)

    def support(self, headers:Dict) -&gt; bool:
        if &#39;content-type&#39; not in headers:
            return False

        for content_type in self.SUPPORTED_CONTENT_TYPES:
            if headers[&#39;content-type&#39;].find(content_type) != -1:
                return True

        return False

    def verify(self, message:bytes, signature:str) -&gt; bool:
        for signing_secret in self._signing_secret:
            if hmac.new(signing_secret, message, hashlib.sha256).hexdigest().upper() == signature:
                return True

        return False

    def read(self, content: bytes, content_encoding:str, content_type:str, signature:Optional[str]) -&gt; Dict:
        if content_encoding == &#39;gzip&#39;:
            import gzip
            content = gzip.decompress(content)
        elif content_encoding == &#39;deflate&#39;:
            import zlib
            content = zlib.decompress(content)
        elif content_encoding == &#39;brotli&#39;:
            import brotli
            content = brotli.decompress(content)

        if self._signing_secret is not None and signature is not None:
            if not self.verify(content, signature):
                raise WebhookSignatureMissMatch()

        if content_type.startswith(&#39;application/json&#39;):
            content = loads(content, cls=self.JSONDateTimeDecoder)
        elif content_type.startswith(&#39;application/msgpack&#39;):
            import msgpack
            content = msgpack.loads(content, object_hook=_date_parser, strict_map_key=False)

        return content

    def __call__(self, content: bytes) -&gt; Union[str, Dict]:
        try:
            return self.content_loader(content)
        except Exception as e:
            try:
                raise EncoderError(content=content.decode(&#39;utf-8&#39;)) from e
            except UnicodeError:
                raise EncoderError(content=base64.b64encode(content).decode(&#39;utf-8&#39;)) from e</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="scrapfly.api_response.ResponseBodyHandler.JSONDateTimeDecoder"><code class="name">var <span class="ident">JSONDateTimeDecoder</span></code></dt>
<dd>
<div class="desc"><p>Simple JSON <a href="http://json.org">http://json.org</a> decoder</p>
<p>Performs the following translations in decoding by default:</p>
<p>+---------------+-------------------+
| JSON
| Python
|
+===============+===================+
| object
| dict
|
+---------------+-------------------+
| array
| list
|
+---------------+-------------------+
| string
| str
|
+---------------+-------------------+
| number (int)
| int
|
+---------------+-------------------+
| number (real) | float
|
+---------------+-------------------+
| true
| True
|
+---------------+-------------------+
| false
| False
|
+---------------+-------------------+
| null
| None
|
+---------------+-------------------+</p>
<p>It also understands <code>NaN</code>, <code>Infinity</code>, and <code>-Infinity</code> as
their corresponding <code>float</code> values, which is outside the JSON spec.</p></div>
</dd>
<dt id="scrapfly.api_response.ResponseBodyHandler.SUPPORTED_COMPRESSION"><code class="name">var <span class="ident">SUPPORTED_COMPRESSION</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="scrapfly.api_response.ResponseBodyHandler.SUPPORTED_CONTENT_TYPES"><code class="name">var <span class="ident">SUPPORTED_CONTENT_TYPES</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="scrapfly.api_response.ResponseBodyHandler.read"><code class="name flex">
<span>def <span class="ident">read</span></span>(<span>self, content: bytes, content_encoding: str, content_type: str, signature: Optional[str]) ‑> Dict</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read(self, content: bytes, content_encoding:str, content_type:str, signature:Optional[str]) -&gt; Dict:
    if content_encoding == &#39;gzip&#39;:
        import gzip
        content = gzip.decompress(content)
    elif content_encoding == &#39;deflate&#39;:
        import zlib
        content = zlib.decompress(content)
    elif content_encoding == &#39;brotli&#39;:
        import brotli
        content = brotli.decompress(content)

    if self._signing_secret is not None and signature is not None:
        if not self.verify(content, signature):
            raise WebhookSignatureMissMatch()

    if content_type.startswith(&#39;application/json&#39;):
        content = loads(content, cls=self.JSONDateTimeDecoder)
    elif content_type.startswith(&#39;application/msgpack&#39;):
        import msgpack
        content = msgpack.loads(content, object_hook=_date_parser, strict_map_key=False)

    return content</code></pre>
</details>
</dd>
<dt id="scrapfly.api_response.ResponseBodyHandler.support"><code class="name flex">
<span>def <span class="ident">support</span></span>(<span>self, headers: Dict) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def support(self, headers:Dict) -&gt; bool:
    if &#39;content-type&#39; not in headers:
        return False

    for content_type in self.SUPPORTED_CONTENT_TYPES:
        if headers[&#39;content-type&#39;].find(content_type) != -1:
            return True

    return False</code></pre>
</details>
</dd>
<dt id="scrapfly.api_response.ResponseBodyHandler.verify"><code class="name flex">
<span>def <span class="ident">verify</span></span>(<span>self, message: bytes, signature: str) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def verify(self, message:bytes, signature:str) -&gt; bool:
    for signing_secret in self._signing_secret:
        if hmac.new(signing_secret, message, hashlib.sha256).hexdigest().upper() == signature:
            return True

    return False</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="scrapfly.api_response.ScrapeApiResponse"><code class="flex name class">
<span>class <span class="ident">ScrapeApiResponse</span></span>
<span>(</span><span>request: requests.models.Request, response: requests.models.Response, scrape_config: <a title="scrapfly.scrape_config.ScrapeConfig" href="scrape_config.html#scrapfly.scrape_config.ScrapeConfig">ScrapeConfig</a>, api_result: Optional[Dict] = None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ScrapeApiResponse:

    def __init__(self, request: Request, response: Response, scrape_config: ScrapeConfig, api_result: Optional[Dict] = None):
        self.request = request
        self.response = response
        self.scrape_config = scrape_config

        if self.scrape_config.method == &#39;HEAD&#39;:
            api_result = {
                &#39;result&#39;: {
                    &#39;request_headers&#39;: {},
                    &#39;status&#39;: &#39;DONE&#39;,
                    &#39;success&#39;: 200 &gt;= self.response.status_code &lt; 300,
                    &#39;response_headers&#39;: self.response.headers,
                    &#39;status_code&#39;: self.response.status_code,
                    &#39;reason&#39;: self.response.reason,
                    &#39;format&#39;: &#39;text&#39;,
                    &#39;content&#39;: &#39;&#39;
                },
                &#39;context&#39;: {},
                &#39;config&#39;: self.scrape_config.__dict__
            }

            if &#39;X-Scrapfly-Reject-Code&#39; in self.response.headers:
                api_result[&#39;result&#39;][&#39;error&#39;] = {
                    &#39;code&#39;: self.response.headers[&#39;X-Scrapfly-Reject-Code&#39;],
                    &#39;http_code&#39;: int(self.response.headers[&#39;X-Scrapfly-Reject-Http-Code&#39;]),
                    &#39;message&#39;: self.response.headers[&#39;X-Scrapfly-Reject-Description&#39;],
                    &#39;error_id&#39;: self.response.headers[&#39;X-Scrapfly-Reject-ID&#39;],
                    &#39;retryable&#39;: True if self.response.headers[&#39;X-Scrapfly-Reject-Retryable&#39;] == &#39;yes&#39; else False,
                    &#39;doc_url&#39;: &#39;&#39;,
                    &#39;links&#39;: {}
                }

                if &#39;X-Scrapfly-Reject-Doc&#39; in self.response.headers:
                    api_result[&#39;result&#39;][&#39;error&#39;][&#39;doc_url&#39;] = self.response.headers[&#39;X-Scrapfly-Reject-Doc&#39;]
                    api_result[&#39;result&#39;][&#39;error&#39;][&#39;links&#39;][&#39;Related Docs&#39;] = self.response.headers[&#39;X-Scrapfly-Reject-Doc&#39;]

        if isinstance(api_result, str):
            raise HttpError(
                request=request,
                response=response,
                message=&#39;Bad gateway&#39;,
                code=502,
                http_status_code=502,
                is_retryable=True
            )

        self.result = self.handle_api_result(api_result=api_result)

    @property
    def scrape_result(self) -&gt; Dict:
        return self.result[&#39;result&#39;]

    @property
    def config(self) -&gt; Dict:
        return self.result[&#39;config&#39;]

    @property
    def context(self) -&gt; Dict:
        return self.result[&#39;context&#39;]

    @property
    def content(self) -&gt; str:
        return self.scrape_result[&#39;content&#39;]

    @property
    def success(self) -&gt; bool:
        &#34;&#34;&#34;
            /!\ Success means Scrapfly api reply correctly to the call, but the scrape can be unsuccessful if the upstream reply with error status code
        &#34;&#34;&#34;
        return 200 &gt;= self.response.status_code &lt;= 299

    @property
    def scrape_success(self) -&gt; bool:
        return self.scrape_result[&#39;success&#39;]

    @property
    def error(self) -&gt; Optional[Dict]:
        if self.scrape_success is False:
            return self.scrape_result[&#39;error&#39;]

    @property
    def status_code(self) -&gt; int:
        &#34;&#34;&#34;
            /!\ This is the status code of our API, not the upstream website
        &#34;&#34;&#34;
        return self.response.status_code

    @property
    def upstream_status_code(self) -&gt; Optional[int]:
        if &#39;status_code&#39; in self.scrape_result:
            return self.scrape_result[&#39;status_code&#39;]

        return None

    def prevent_extra_usage(self):
        if self.remaining_quota == 0:
            raise ExtraUsageForbidden(
                message=&#39;All Pre Paid Quota Used&#39;,
                code=&#39;ERR::ACCOUNT::PREVENT_EXTRA_USAGE&#39;,
                http_status_code=429,
                is_retryable=False
            )

    @property
    def remaining_quota(self) -&gt; Optional[int]:
        remaining_scrape = self.response.headers.get(&#39;X-Scrapfly-Remaining-Scrape&#39;)

        if remaining_scrape:
            remaining_scrape = int(remaining_scrape)

        return remaining_scrape

    @property
    def cost(self) -&gt; Optional[int]:
        cost = self.response.headers.get(&#39;X-Scrapfly-Api-Cost&#39;)

        if cost:
            cost = int(cost)

        return cost

    @property
    def duration_ms(self) -&gt; Optional[float]:
        duration = self.response.headers.get(&#39;X-Scrapfly-Response-Time&#39;)

        if duration:
            duration = float(duration)

        return duration

    @property
    def headers(self) -&gt; CaseInsensitiveDict:
        return self.response.headers

    def handle_api_result(self, api_result: Dict) -&gt; Optional[FrozenDict]:
        if self._is_api_error(api_result=api_result) is True:
            return FrozenDict(api_result)

        try:
            if isinstance(api_result[&#39;config&#39;][&#39;headers&#39;], list):
                api_result[&#39;config&#39;][&#39;headers&#39;] = {}
        except TypeError:
            logger.info(api_result)
            raise

        with suppress(KeyError):
            api_result[&#39;result&#39;][&#39;request_headers&#39;] = CaseInsensitiveDict(api_result[&#39;result&#39;][&#39;request_headers&#39;])
            api_result[&#39;result&#39;][&#39;response_headers&#39;] = CaseInsensitiveDict(api_result[&#39;result&#39;][&#39;response_headers&#39;])

        if api_result[&#39;result&#39;][&#39;format&#39;] == &#39;binary&#39; and api_result[&#39;result&#39;][&#39;content&#39;]:
            api_result[&#39;result&#39;][&#39;content&#39;] = BytesIO(b64decode(api_result[&#39;result&#39;][&#39;content&#39;]))

        return FrozenDict(api_result)

    @cached_property
    def soup(self) -&gt; &#39;BeautifulSoup&#39;:
        try:
            from bs4 import BeautifulSoup
            soup = BeautifulSoup(self.content, &#34;lxml&#34;)
            return soup
        except ImportError as e:
            logger.error(&#39;You must install scrapfly[parser] to enable this feature&#39;)

    @cached_property
    def selector(self) -&gt; &#39;Selector&#39;:
        try:
            from parsel import Selector
            return Selector(text=self.content)
        except ImportError as e:
            logger.error(&#39;You must install parsel or scrapy package to enable this feature&#39;)
            raise e

    @property
    def error_message(self) :
        if self.error:
            message = &#34;&lt;-- %s | %s - %s.&#34; % (self.response.status_code, self.error[&#39;code&#39;], self.error[&#39;message&#39;])

            if self.error[&#39;links&#39;]:
                message += &#34;Checkout the related doc: %s&#34; % list(self.error[&#39;links&#39;].values())[0]

            return message

        return &#39;&lt;-- %s - %s %s | Doc: %s&#39; % (self.response.status_code, self.http_status_code, self.code, self.documentation_url)

    def _is_api_error(self, api_result: Dict) -&gt; bool:
        if self.scrape_config.method == &#39;HEAD&#39;:
            if &#39;X-Reject-Reason&#39; in self.response.headers:
                return True
            return False

        if api_result is None:
            return True

        return &#39;error_id&#39; in api_result

    def raise_for_result(self, raise_on_upstream_error: bool = True):

        try:
            self.response.raise_for_status()
        except HTTPError as e:
            if &#39;http_code&#39; in self.result:
                if e.response.status_code &gt;= 500:
                    raise ApiHttpServerError(
                        request=e.request,
                        response=e.response,
                        message=self.result[&#39;message&#39;],
                        code=&#39;&#39;,
                        resource=&#39;&#39;,
                        http_status_code=e.response.status_code,
                        documentation_url=self.result.get(&#39;links&#39;)
                    ) from e
                else:
                    raise ApiHttpClientError(
                        request=e.request,
                        response=e.response,
                        message=self.result[&#39;message&#39;],
                        code=&#39;&#39;,
                        resource=&#39;API&#39;,
                        http_status_code=self.result[&#39;http_code&#39;],
                        documentation_url=self.result.get(&#39;links&#39;)
                    ) from e

        if self.result[&#39;result&#39;][&#39;status&#39;] == &#39;DONE&#39; and self.scrape_success is False:
            error = ErrorFactory.create(api_response=self)

            if error:
                if isinstance(error, UpstreamHttpError):
                    if raise_on_upstream_error is True:
                        raise error
                else:
                    raise error

    def upstream_result_into_response(self, _class=Response) -&gt; Optional[Response]:
        if _class != Response:
            raise RuntimeError(&#39;only Response from requests package is supported at the moment&#39;)

        if self.result is None:
            return None

        if self.response.status_code != 200:
            return None

        response = Response()
        response.status_code = self.scrape_result[&#39;status_code&#39;]
        response.reason = self.scrape_result[&#39;reason&#39;]

        if self.scrape_result[&#39;content&#39;]:
            if isinstance(self.scrape_result[&#39;content&#39;], BytesIO):
                response._content = self.scrape_result[&#39;content&#39;].getvalue()
            elif isinstance(self.scrape_result[&#39;content&#39;], bytes):
                response._content = self.scrape_result[&#39;content&#39;]
            elif isinstance(self.scrape_result[&#39;content&#39;], str):
                response._content = self.scrape_result[&#39;content&#39;].encode(&#39;utf-8&#39;)
        else:
            response._content = None

        response.headers.update(self.scrape_result[&#39;response_headers&#39;])
        response.url = self.scrape_result[&#39;url&#39;]

        response.request = Request(
            method=self.config[&#39;method&#39;],
            url=self.config[&#39;url&#39;],
            headers=self.scrape_result[&#39;request_headers&#39;],
            data=self.config[&#39;body&#39;] if self.config[&#39;body&#39;] else None
        )

        if &#39;set-cookie&#39; in response.headers:
            for raw_cookie in response.headers[&#39;set-cookie&#39;]:
                for name, cookie in SimpleCookie(raw_cookie).items():
                    expires = cookie.get(&#39;expires&#39;)

                    if expires == &#39;&#39;:
                        expires = None

                    if expires:
                        try:
                            expires = parse(expires).timestamp()
                        except ValueError:
                            expires = None

                    if type(expires) == str:
                        if &#39;.&#39; in expires:
                            expires = float(expires)
                        else:
                            expires = int(expires)

                    response.cookies.set_cookie(Cookie(
                        version=cookie.get(&#39;version&#39;) if cookie.get(&#39;version&#39;) else None,
                        name=name,
                        value=cookie.value,
                        path=cookie.get(&#39;path&#39;, &#39;&#39;),
                        expires=expires,
                        comment=cookie.get(&#39;comment&#39;),
                        domain=cookie.get(&#39;domain&#39;, &#39;&#39;),
                        secure=cookie.get(&#39;secure&#39;),
                        port=None,
                        port_specified=False,
                        domain_specified=cookie.get(&#39;domain&#39;) is not None and cookie.get(&#39;domain&#39;) != &#39;&#39;,
                        domain_initial_dot=bool(cookie.get(&#39;domain&#39;).startswith(&#39;.&#39;)) if cookie.get(&#39;domain&#39;) is not None else False,
                        path_specified=cookie.get(&#39;path&#39;) != &#39;&#39; and cookie.get(&#39;path&#39;) is not None,
                        discard=False,
                        comment_url=None,
                        rest={
                            &#39;httponly&#39;: cookie.get(&#39;httponly&#39;),
                            &#39;samesite&#39;: cookie.get(&#39;samesite&#39;),
                            &#39;max-age&#39;: cookie.get(&#39;max-age&#39;)
                        }
                    ))

        return response

    def sink(self, path: Optional[str] = None, name: Optional[str] = None, file: Optional[Union[TextIO, BytesIO]] = None, content:Optional[Union[str, bytes]]=None):
        file_content = content or self.scrape_result[&#39;content&#39;]
        file_path = None
        file_extension = None

        if name:
            name_parts = name.split(&#39;.&#39;)
            if len(name_parts) &gt; 1:
                file_extension = name_parts[-1]

        if not file:
            if file_extension is None:
                try:
                    mime_type = self.scrape_result[&#39;response_headers&#39;][&#39;content-type&#39;]
                except KeyError:
                    mime_type = &#39;application/octet-stream&#39;

                if &#39;;&#39; in mime_type:
                    mime_type = mime_type.split(&#39;;&#39;)[0]

                file_extension = &#39;.&#39; + mime_type.split(&#39;/&#39;)[1]

            if not name:
                name = self.config[&#39;url&#39;].split(&#39;/&#39;)[-1]

            if name.find(file_extension) == -1:
                name += file_extension

            file_path = path + &#39;/&#39; + name if path is not None else name

            if file_path == file_extension:
                url = re.sub(r&#39;(https|http)?://&#39;, &#39;&#39;, self.config[&#39;url&#39;]).replace(&#39;/&#39;, &#39;-&#39;)

                if url[-1] == &#39;-&#39;:
                    url = url[:-1]

                url += file_extension

                file_path = url

            file = open(file_path, &#39;wb&#39;)

        if isinstance(file_content, str):
            file_content = BytesIO(file_content.encode(&#39;utf-8&#39;))
        elif isinstance(file_content, bytes):
            file_content = BytesIO(file_content)

        file_content.seek(0)
        with file as f:
            shutil.copyfileobj(file_content, f, length=131072)

        logger.info(&#39;file %s created&#39; % file_path)</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="scrapfly.api_response.ScrapeApiResponse.config"><code class="name">var <span class="ident">config</span> : Dict</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def config(self) -&gt; Dict:
    return self.result[&#39;config&#39;]</code></pre>
</details>
</dd>
<dt id="scrapfly.api_response.ScrapeApiResponse.content"><code class="name">var <span class="ident">content</span> : str</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def content(self) -&gt; str:
    return self.scrape_result[&#39;content&#39;]</code></pre>
</details>
</dd>
<dt id="scrapfly.api_response.ScrapeApiResponse.context"><code class="name">var <span class="ident">context</span> : Dict</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def context(self) -&gt; Dict:
    return self.result[&#39;context&#39;]</code></pre>
</details>
</dd>
<dt id="scrapfly.api_response.ScrapeApiResponse.cost"><code class="name">var <span class="ident">cost</span> : Optional[int]</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def cost(self) -&gt; Optional[int]:
    cost = self.response.headers.get(&#39;X-Scrapfly-Api-Cost&#39;)

    if cost:
        cost = int(cost)

    return cost</code></pre>
</details>
</dd>
<dt id="scrapfly.api_response.ScrapeApiResponse.duration_ms"><code class="name">var <span class="ident">duration_ms</span> : Optional[float]</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def duration_ms(self) -&gt; Optional[float]:
    duration = self.response.headers.get(&#39;X-Scrapfly-Response-Time&#39;)

    if duration:
        duration = float(duration)

    return duration</code></pre>
</details>
</dd>
<dt id="scrapfly.api_response.ScrapeApiResponse.error"><code class="name">var <span class="ident">error</span> : Optional[Dict]</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def error(self) -&gt; Optional[Dict]:
    if self.scrape_success is False:
        return self.scrape_result[&#39;error&#39;]</code></pre>
</details>
</dd>
<dt id="scrapfly.api_response.ScrapeApiResponse.error_message"><code class="name">var <span class="ident">error_message</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def error_message(self) :
    if self.error:
        message = &#34;&lt;-- %s | %s - %s.&#34; % (self.response.status_code, self.error[&#39;code&#39;], self.error[&#39;message&#39;])

        if self.error[&#39;links&#39;]:
            message += &#34;Checkout the related doc: %s&#34; % list(self.error[&#39;links&#39;].values())[0]

        return message

    return &#39;&lt;-- %s - %s %s | Doc: %s&#39; % (self.response.status_code, self.http_status_code, self.code, self.documentation_url)</code></pre>
</details>
</dd>
<dt id="scrapfly.api_response.ScrapeApiResponse.headers"><code class="name">var <span class="ident">headers</span> : requests.structures.CaseInsensitiveDict</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def headers(self) -&gt; CaseInsensitiveDict:
    return self.response.headers</code></pre>
</details>
</dd>
<dt id="scrapfly.api_response.ScrapeApiResponse.remaining_quota"><code class="name">var <span class="ident">remaining_quota</span> : Optional[int]</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def remaining_quota(self) -&gt; Optional[int]:
    remaining_scrape = self.response.headers.get(&#39;X-Scrapfly-Remaining-Scrape&#39;)

    if remaining_scrape:
        remaining_scrape = int(remaining_scrape)

    return remaining_scrape</code></pre>
</details>
</dd>
<dt id="scrapfly.api_response.ScrapeApiResponse.scrape_result"><code class="name">var <span class="ident">scrape_result</span> : Dict</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def scrape_result(self) -&gt; Dict:
    return self.result[&#39;result&#39;]</code></pre>
</details>
</dd>
<dt id="scrapfly.api_response.ScrapeApiResponse.scrape_success"><code class="name">var <span class="ident">scrape_success</span> : bool</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def scrape_success(self) -&gt; bool:
    return self.scrape_result[&#39;success&#39;]</code></pre>
</details>
</dd>
<dt id="scrapfly.api_response.ScrapeApiResponse.selector"><code class="name">var <span class="ident">selector</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def __get__(self, instance, owner=None):
    if instance is None:
        return self
    if self.attrname is None:
        raise TypeError(
            &#34;Cannot use cached_property instance without calling __set_name__ on it.&#34;)
    try:
        cache = instance.__dict__
    except AttributeError:  # not all objects have __dict__ (e.g. class defines slots)
        msg = (
            f&#34;No &#39;__dict__&#39; attribute on {type(instance).__name__!r} &#34;
            f&#34;instance to cache {self.attrname!r} property.&#34;
        )
        raise TypeError(msg) from None
    val = cache.get(self.attrname, _NOT_FOUND)
    if val is _NOT_FOUND:
        with self.lock:
            # check if another thread filled cache while we awaited lock
            val = cache.get(self.attrname, _NOT_FOUND)
            if val is _NOT_FOUND:
                val = self.func(instance)
                try:
                    cache[self.attrname] = val
                except TypeError:
                    msg = (
                        f&#34;The &#39;__dict__&#39; attribute on {type(instance).__name__!r} instance &#34;
                        f&#34;does not support item assignment for caching {self.attrname!r} property.&#34;
                    )
                    raise TypeError(msg) from None
    return val</code></pre>
</details>
</dd>
<dt id="scrapfly.api_response.ScrapeApiResponse.soup"><code class="name">var <span class="ident">soup</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def __get__(self, instance, owner=None):
    if instance is None:
        return self
    if self.attrname is None:
        raise TypeError(
            &#34;Cannot use cached_property instance without calling __set_name__ on it.&#34;)
    try:
        cache = instance.__dict__
    except AttributeError:  # not all objects have __dict__ (e.g. class defines slots)
        msg = (
            f&#34;No &#39;__dict__&#39; attribute on {type(instance).__name__!r} &#34;
            f&#34;instance to cache {self.attrname!r} property.&#34;
        )
        raise TypeError(msg) from None
    val = cache.get(self.attrname, _NOT_FOUND)
    if val is _NOT_FOUND:
        with self.lock:
            # check if another thread filled cache while we awaited lock
            val = cache.get(self.attrname, _NOT_FOUND)
            if val is _NOT_FOUND:
                val = self.func(instance)
                try:
                    cache[self.attrname] = val
                except TypeError:
                    msg = (
                        f&#34;The &#39;__dict__&#39; attribute on {type(instance).__name__!r} instance &#34;
                        f&#34;does not support item assignment for caching {self.attrname!r} property.&#34;
                    )
                    raise TypeError(msg) from None
    return val</code></pre>
</details>
</dd>
<dt id="scrapfly.api_response.ScrapeApiResponse.status_code"><code class="name">var <span class="ident">status_code</span> : int</code></dt>
<dd>
<div class="desc"><p>/!\ This is the status code of our API, not the upstream website</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def status_code(self) -&gt; int:
    &#34;&#34;&#34;
        /!\ This is the status code of our API, not the upstream website
    &#34;&#34;&#34;
    return self.response.status_code</code></pre>
</details>
</dd>
<dt id="scrapfly.api_response.ScrapeApiResponse.success"><code class="name">var <span class="ident">success</span> : bool</code></dt>
<dd>
<div class="desc"><p>/!\ Success means Scrapfly api reply correctly to the call, but the scrape can be unsuccessful if the upstream reply with error status code</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def success(self) -&gt; bool:
    &#34;&#34;&#34;
        /!\ Success means Scrapfly api reply correctly to the call, but the scrape can be unsuccessful if the upstream reply with error status code
    &#34;&#34;&#34;
    return 200 &gt;= self.response.status_code &lt;= 299</code></pre>
</details>
</dd>
<dt id="scrapfly.api_response.ScrapeApiResponse.upstream_status_code"><code class="name">var <span class="ident">upstream_status_code</span> : Optional[int]</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def upstream_status_code(self) -&gt; Optional[int]:
    if &#39;status_code&#39; in self.scrape_result:
        return self.scrape_result[&#39;status_code&#39;]

    return None</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="scrapfly.api_response.ScrapeApiResponse.handle_api_result"><code class="name flex">
<span>def <span class="ident">handle_api_result</span></span>(<span>self, api_result: Dict) ‑> Optional[<a title="scrapfly.frozen_dict.FrozenDict" href="frozen_dict.html#scrapfly.frozen_dict.FrozenDict">FrozenDict</a>]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def handle_api_result(self, api_result: Dict) -&gt; Optional[FrozenDict]:
    if self._is_api_error(api_result=api_result) is True:
        return FrozenDict(api_result)

    try:
        if isinstance(api_result[&#39;config&#39;][&#39;headers&#39;], list):
            api_result[&#39;config&#39;][&#39;headers&#39;] = {}
    except TypeError:
        logger.info(api_result)
        raise

    with suppress(KeyError):
        api_result[&#39;result&#39;][&#39;request_headers&#39;] = CaseInsensitiveDict(api_result[&#39;result&#39;][&#39;request_headers&#39;])
        api_result[&#39;result&#39;][&#39;response_headers&#39;] = CaseInsensitiveDict(api_result[&#39;result&#39;][&#39;response_headers&#39;])

    if api_result[&#39;result&#39;][&#39;format&#39;] == &#39;binary&#39; and api_result[&#39;result&#39;][&#39;content&#39;]:
        api_result[&#39;result&#39;][&#39;content&#39;] = BytesIO(b64decode(api_result[&#39;result&#39;][&#39;content&#39;]))

    return FrozenDict(api_result)</code></pre>
</details>
</dd>
<dt id="scrapfly.api_response.ScrapeApiResponse.prevent_extra_usage"><code class="name flex">
<span>def <span class="ident">prevent_extra_usage</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prevent_extra_usage(self):
    if self.remaining_quota == 0:
        raise ExtraUsageForbidden(
            message=&#39;All Pre Paid Quota Used&#39;,
            code=&#39;ERR::ACCOUNT::PREVENT_EXTRA_USAGE&#39;,
            http_status_code=429,
            is_retryable=False
        )</code></pre>
</details>
</dd>
<dt id="scrapfly.api_response.ScrapeApiResponse.raise_for_result"><code class="name flex">
<span>def <span class="ident">raise_for_result</span></span>(<span>self, raise_on_upstream_error: bool = True)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def raise_for_result(self, raise_on_upstream_error: bool = True):

    try:
        self.response.raise_for_status()
    except HTTPError as e:
        if &#39;http_code&#39; in self.result:
            if e.response.status_code &gt;= 500:
                raise ApiHttpServerError(
                    request=e.request,
                    response=e.response,
                    message=self.result[&#39;message&#39;],
                    code=&#39;&#39;,
                    resource=&#39;&#39;,
                    http_status_code=e.response.status_code,
                    documentation_url=self.result.get(&#39;links&#39;)
                ) from e
            else:
                raise ApiHttpClientError(
                    request=e.request,
                    response=e.response,
                    message=self.result[&#39;message&#39;],
                    code=&#39;&#39;,
                    resource=&#39;API&#39;,
                    http_status_code=self.result[&#39;http_code&#39;],
                    documentation_url=self.result.get(&#39;links&#39;)
                ) from e

    if self.result[&#39;result&#39;][&#39;status&#39;] == &#39;DONE&#39; and self.scrape_success is False:
        error = ErrorFactory.create(api_response=self)

        if error:
            if isinstance(error, UpstreamHttpError):
                if raise_on_upstream_error is True:
                    raise error
            else:
                raise error</code></pre>
</details>
</dd>
<dt id="scrapfly.api_response.ScrapeApiResponse.sink"><code class="name flex">
<span>def <span class="ident">sink</span></span>(<span>self, path: Optional[str] = None, name: Optional[str] = None, file: Union[TextIO, _io.BytesIO, ForwardRef(None)] = None, content: Union[str, bytes, ForwardRef(None)] = None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sink(self, path: Optional[str] = None, name: Optional[str] = None, file: Optional[Union[TextIO, BytesIO]] = None, content:Optional[Union[str, bytes]]=None):
    file_content = content or self.scrape_result[&#39;content&#39;]
    file_path = None
    file_extension = None

    if name:
        name_parts = name.split(&#39;.&#39;)
        if len(name_parts) &gt; 1:
            file_extension = name_parts[-1]

    if not file:
        if file_extension is None:
            try:
                mime_type = self.scrape_result[&#39;response_headers&#39;][&#39;content-type&#39;]
            except KeyError:
                mime_type = &#39;application/octet-stream&#39;

            if &#39;;&#39; in mime_type:
                mime_type = mime_type.split(&#39;;&#39;)[0]

            file_extension = &#39;.&#39; + mime_type.split(&#39;/&#39;)[1]

        if not name:
            name = self.config[&#39;url&#39;].split(&#39;/&#39;)[-1]

        if name.find(file_extension) == -1:
            name += file_extension

        file_path = path + &#39;/&#39; + name if path is not None else name

        if file_path == file_extension:
            url = re.sub(r&#39;(https|http)?://&#39;, &#39;&#39;, self.config[&#39;url&#39;]).replace(&#39;/&#39;, &#39;-&#39;)

            if url[-1] == &#39;-&#39;:
                url = url[:-1]

            url += file_extension

            file_path = url

        file = open(file_path, &#39;wb&#39;)

    if isinstance(file_content, str):
        file_content = BytesIO(file_content.encode(&#39;utf-8&#39;))
    elif isinstance(file_content, bytes):
        file_content = BytesIO(file_content)

    file_content.seek(0)
    with file as f:
        shutil.copyfileobj(file_content, f, length=131072)

    logger.info(&#39;file %s created&#39; % file_path)</code></pre>
</details>
</dd>
<dt id="scrapfly.api_response.ScrapeApiResponse.upstream_result_into_response"><code class="name flex">
<span>def <span class="ident">upstream_result_into_response</span></span>(<span>self) ‑> Optional[requests.models.Response]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def upstream_result_into_response(self, _class=Response) -&gt; Optional[Response]:
    if _class != Response:
        raise RuntimeError(&#39;only Response from requests package is supported at the moment&#39;)

    if self.result is None:
        return None

    if self.response.status_code != 200:
        return None

    response = Response()
    response.status_code = self.scrape_result[&#39;status_code&#39;]
    response.reason = self.scrape_result[&#39;reason&#39;]

    if self.scrape_result[&#39;content&#39;]:
        if isinstance(self.scrape_result[&#39;content&#39;], BytesIO):
            response._content = self.scrape_result[&#39;content&#39;].getvalue()
        elif isinstance(self.scrape_result[&#39;content&#39;], bytes):
            response._content = self.scrape_result[&#39;content&#39;]
        elif isinstance(self.scrape_result[&#39;content&#39;], str):
            response._content = self.scrape_result[&#39;content&#39;].encode(&#39;utf-8&#39;)
    else:
        response._content = None

    response.headers.update(self.scrape_result[&#39;response_headers&#39;])
    response.url = self.scrape_result[&#39;url&#39;]

    response.request = Request(
        method=self.config[&#39;method&#39;],
        url=self.config[&#39;url&#39;],
        headers=self.scrape_result[&#39;request_headers&#39;],
        data=self.config[&#39;body&#39;] if self.config[&#39;body&#39;] else None
    )

    if &#39;set-cookie&#39; in response.headers:
        for raw_cookie in response.headers[&#39;set-cookie&#39;]:
            for name, cookie in SimpleCookie(raw_cookie).items():
                expires = cookie.get(&#39;expires&#39;)

                if expires == &#39;&#39;:
                    expires = None

                if expires:
                    try:
                        expires = parse(expires).timestamp()
                    except ValueError:
                        expires = None

                if type(expires) == str:
                    if &#39;.&#39; in expires:
                        expires = float(expires)
                    else:
                        expires = int(expires)

                response.cookies.set_cookie(Cookie(
                    version=cookie.get(&#39;version&#39;) if cookie.get(&#39;version&#39;) else None,
                    name=name,
                    value=cookie.value,
                    path=cookie.get(&#39;path&#39;, &#39;&#39;),
                    expires=expires,
                    comment=cookie.get(&#39;comment&#39;),
                    domain=cookie.get(&#39;domain&#39;, &#39;&#39;),
                    secure=cookie.get(&#39;secure&#39;),
                    port=None,
                    port_specified=False,
                    domain_specified=cookie.get(&#39;domain&#39;) is not None and cookie.get(&#39;domain&#39;) != &#39;&#39;,
                    domain_initial_dot=bool(cookie.get(&#39;domain&#39;).startswith(&#39;.&#39;)) if cookie.get(&#39;domain&#39;) is not None else False,
                    path_specified=cookie.get(&#39;path&#39;) != &#39;&#39; and cookie.get(&#39;path&#39;) is not None,
                    discard=False,
                    comment_url=None,
                    rest={
                        &#39;httponly&#39;: cookie.get(&#39;httponly&#39;),
                        &#39;samesite&#39;: cookie.get(&#39;samesite&#39;),
                        &#39;max-age&#39;: cookie.get(&#39;max-age&#39;)
                    }
                ))

    return response</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="scrapfly" href="index.html">scrapfly</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="scrapfly.api_response.ResponseBodyHandler" href="#scrapfly.api_response.ResponseBodyHandler">ResponseBodyHandler</a></code></h4>
<ul class="">
<li><code><a title="scrapfly.api_response.ResponseBodyHandler.JSONDateTimeDecoder" href="#scrapfly.api_response.ResponseBodyHandler.JSONDateTimeDecoder">JSONDateTimeDecoder</a></code></li>
<li><code><a title="scrapfly.api_response.ResponseBodyHandler.SUPPORTED_COMPRESSION" href="#scrapfly.api_response.ResponseBodyHandler.SUPPORTED_COMPRESSION">SUPPORTED_COMPRESSION</a></code></li>
<li><code><a title="scrapfly.api_response.ResponseBodyHandler.SUPPORTED_CONTENT_TYPES" href="#scrapfly.api_response.ResponseBodyHandler.SUPPORTED_CONTENT_TYPES">SUPPORTED_CONTENT_TYPES</a></code></li>
<li><code><a title="scrapfly.api_response.ResponseBodyHandler.read" href="#scrapfly.api_response.ResponseBodyHandler.read">read</a></code></li>
<li><code><a title="scrapfly.api_response.ResponseBodyHandler.support" href="#scrapfly.api_response.ResponseBodyHandler.support">support</a></code></li>
<li><code><a title="scrapfly.api_response.ResponseBodyHandler.verify" href="#scrapfly.api_response.ResponseBodyHandler.verify">verify</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="scrapfly.api_response.ScrapeApiResponse" href="#scrapfly.api_response.ScrapeApiResponse">ScrapeApiResponse</a></code></h4>
<ul class="">
<li><code><a title="scrapfly.api_response.ScrapeApiResponse.config" href="#scrapfly.api_response.ScrapeApiResponse.config">config</a></code></li>
<li><code><a title="scrapfly.api_response.ScrapeApiResponse.content" href="#scrapfly.api_response.ScrapeApiResponse.content">content</a></code></li>
<li><code><a title="scrapfly.api_response.ScrapeApiResponse.context" href="#scrapfly.api_response.ScrapeApiResponse.context">context</a></code></li>
<li><code><a title="scrapfly.api_response.ScrapeApiResponse.cost" href="#scrapfly.api_response.ScrapeApiResponse.cost">cost</a></code></li>
<li><code><a title="scrapfly.api_response.ScrapeApiResponse.duration_ms" href="#scrapfly.api_response.ScrapeApiResponse.duration_ms">duration_ms</a></code></li>
<li><code><a title="scrapfly.api_response.ScrapeApiResponse.error" href="#scrapfly.api_response.ScrapeApiResponse.error">error</a></code></li>
<li><code><a title="scrapfly.api_response.ScrapeApiResponse.error_message" href="#scrapfly.api_response.ScrapeApiResponse.error_message">error_message</a></code></li>
<li><code><a title="scrapfly.api_response.ScrapeApiResponse.handle_api_result" href="#scrapfly.api_response.ScrapeApiResponse.handle_api_result">handle_api_result</a></code></li>
<li><code><a title="scrapfly.api_response.ScrapeApiResponse.headers" href="#scrapfly.api_response.ScrapeApiResponse.headers">headers</a></code></li>
<li><code><a title="scrapfly.api_response.ScrapeApiResponse.prevent_extra_usage" href="#scrapfly.api_response.ScrapeApiResponse.prevent_extra_usage">prevent_extra_usage</a></code></li>
<li><code><a title="scrapfly.api_response.ScrapeApiResponse.raise_for_result" href="#scrapfly.api_response.ScrapeApiResponse.raise_for_result">raise_for_result</a></code></li>
<li><code><a title="scrapfly.api_response.ScrapeApiResponse.remaining_quota" href="#scrapfly.api_response.ScrapeApiResponse.remaining_quota">remaining_quota</a></code></li>
<li><code><a title="scrapfly.api_response.ScrapeApiResponse.scrape_result" href="#scrapfly.api_response.ScrapeApiResponse.scrape_result">scrape_result</a></code></li>
<li><code><a title="scrapfly.api_response.ScrapeApiResponse.scrape_success" href="#scrapfly.api_response.ScrapeApiResponse.scrape_success">scrape_success</a></code></li>
<li><code><a title="scrapfly.api_response.ScrapeApiResponse.selector" href="#scrapfly.api_response.ScrapeApiResponse.selector">selector</a></code></li>
<li><code><a title="scrapfly.api_response.ScrapeApiResponse.sink" href="#scrapfly.api_response.ScrapeApiResponse.sink">sink</a></code></li>
<li><code><a title="scrapfly.api_response.ScrapeApiResponse.soup" href="#scrapfly.api_response.ScrapeApiResponse.soup">soup</a></code></li>
<li><code><a title="scrapfly.api_response.ScrapeApiResponse.status_code" href="#scrapfly.api_response.ScrapeApiResponse.status_code">status_code</a></code></li>
<li><code><a title="scrapfly.api_response.ScrapeApiResponse.success" href="#scrapfly.api_response.ScrapeApiResponse.success">success</a></code></li>
<li><code><a title="scrapfly.api_response.ScrapeApiResponse.upstream_result_into_response" href="#scrapfly.api_response.ScrapeApiResponse.upstream_result_into_response">upstream_result_into_response</a></code></li>
<li><code><a title="scrapfly.api_response.ScrapeApiResponse.upstream_status_code" href="#scrapfly.api_response.ScrapeApiResponse.upstream_status_code">upstream_status_code</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>